{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85ad3d1",
   "metadata": {},
   "source": [
    "# OCR\n",
    "This project implements OCR for the first 10 pages of a general PDF. This program will be compatiable with SQL.\n",
    "\n",
    "### Things to Note\n",
    "- to use a juypter notebook in vs code through uv, you must do these things:\n",
    "    - uv init the project\n",
    "    - create a venv\n",
    "    - uv add --dev ipykernel\n",
    "    - in vs code when selecting a kernel for the notebook, select pyhton then your venv\n",
    "- Using `easyocr`\n",
    "    - in order to read pdf documents, I've had to using the package pdf2image which requires poppler binary files which are attached in this project\n",
    "    - this introduces system a system depency with the bin files\n",
    "    - also I've been experiencing some crashing on my computer due to the model running on my cpu I think\n",
    "    - I have a gpu though I'm not exactly sure how to get it to run on there\n",
    "    - it would be most ideal if I could use google colabs gpus (I already have an account with them)\n",
    "    - using easyocr automatically uses a cpu version of torch, even tried to uninstall easyocr and download a cuda 12.6 torch version\n",
    "      but \"uv add easyocr\" deletes gpu version and reinstalls cpu version\n",
    "\n",
    "### Next Steps\n",
    "- increase computation speed (switch to gpu)\n",
    "- visualize which words are read on pdf (box detected letters)\n",
    "- add compatability with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b6f546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dsbor\\OneDrive\\Desktop\\Personal\\Davis-PDF-Extraction\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# check env\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f47f5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if gpu is there\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a28175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing easyocr\n",
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "result = reader.readtext('good_ex.jpg')\n",
    "\n",
    "for (bbox, text, prob) in result:\n",
    "    print(f\"Text: {text}, Probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing pdf to image conversion\n",
    "from pdf2image import convert_from_path\n",
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "pages = convert_from_path('HW3-1.pdf', poppler_path=r'poppler_bin', first_page=1, last_page=10)\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "for i, page_image in enumerate(pages, start=1):\n",
    "    # convert PIL image to np array\n",
    "    img_np = np.array(page_image)\n",
    "\n",
    "    result = reader.readtext(img_np)\n",
    "\n",
    "    print(f\"\\n--- Text on page {i} ---\")\n",
    "    for bbox, text, prob in result:\n",
    "        #print(f'Text: {text}, Probability: {prob:.4f}')\n",
    "        print(f\"{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e868632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it all together and boxing and saving what is reconginzed\n",
    "from pdf2image import convert_from_path\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "pages = convert_from_path('example.pdf', poppler_path=r'poppler_bin', first_page=1, last_page=10)\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "for i, page_image in enumerate(pages, start=1):\n",
    "    \n",
    "    img_np = np.array(page_image)\n",
    "    img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    result = reader.readtext(img_np)\n",
    "\n",
    "    for bbox, text, prob in result:\n",
    "        \n",
    "        pts = np.array(bbox, dtype=np.int32)\n",
    "        cv2.polylines(img_cv, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        top_left = tuple(pts[0])\n",
    "        cv2.putText(img_cv, text, (top_left[0], top_left[1]-5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imwrite(f'page_{i}_boxed.png', img_cv)\n",
    "\n",
    "    print(f\"Page {i} processed, saved as page_{i}_boxed.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd55c7e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(cv2.__version__)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36535863",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytesseract\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# If needed on Windows:\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\u001b[39;00m\n\u001b[32m      9\u001b[39m pages = convert_from_path(\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexample.pdf\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m     poppler_path=\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpoppler_bin\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m     first_page=\u001b[32m1\u001b[39m,\n\u001b[32m     13\u001b[39m     last_page=\u001b[32m10\u001b[39m\n\u001b[32m     14\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# If needed on Windows:\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "pages = convert_from_path(\n",
    "    'example.pdf',\n",
    "    poppler_path=r'poppler_bin',\n",
    "    first_page=1,\n",
    "    last_page=10\n",
    ")\n",
    "\n",
    "for i, page_image in enumerate(pages, start=1):\n",
    "\n",
    "    img_np = np.array(page_image)\n",
    "    img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # OCR with bounding boxes\n",
    "    data = pytesseract.image_to_data(\n",
    "        img_cv,\n",
    "        lang='eng',\n",
    "        output_type=pytesseract.Output.DICT\n",
    "    )\n",
    "\n",
    "    n_boxes = len(data['text'])\n",
    "\n",
    "    for j in range(n_boxes):\n",
    "        text = data['text'][j].strip()\n",
    "        conf = int(data['conf'][j])\n",
    "\n",
    "        # Skip empty or low-confidence text\n",
    "        if text == \"\" or conf < 40:\n",
    "            continue\n",
    "\n",
    "        x = data['left'][j]\n",
    "        y = data['top'][j]\n",
    "        w = data['width'][j]\n",
    "        h = data['height'][j]\n",
    "\n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(\n",
    "            img_cv,\n",
    "            (x, y),\n",
    "            (x + w, y + h),\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        # Put recognized text\n",
    "        cv2.putText(\n",
    "            img_cv,\n",
    "            text,\n",
    "            (x, y - 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 255),\n",
    "            1,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "    cv2.imwrite(f'page_{i}_boxed.png', img_cv)\n",
    "    print(f\"Page {i} processed, saved as page_{i}_boxed.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
